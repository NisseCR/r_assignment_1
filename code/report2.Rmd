---
title: "Bike Sharing"
author: "Aga, Karla, Nisse, Ole"
date: "`r Sys.Date()`"
output: 
  html_document:
    theme: united
    number_sections: false
    toc: true
    toc_float:
      collapsed: true
    df_print: paged
bibliography: references.bib  
---

<style>
body {
text-align: justify}
</style>

# Abstract
![](../images/bike_sharing.jpeg)  

"*Bikesharing contributes to the advent of more sustainable transportation in cities around the globe.*" [@beland]. Bikesharing programs are designed to provide short-term bicycle rental in stations dispersed throughout the cities and located near public transportation hubs [@beland]. They have numerous environmental and health benefits, such as reducing congestion, complementing other forms of public transportation and encouraging exercise [@beland]. Additionally, accessible bike rental has a lower barrier of entry than purchasing your own bike and is more convenient for out-of-town commuters.  

In principle bicycles pose a good substitute for car use in urban areas, however, they have certain limitations. Among them is the exposure of cyclists to weather while commuting compared to other means of transportation. It would be intuitive for the number of bike rentals to be dependent on current weather conditions. If that is the case, the extent of that relationship would be important information for the bikesharing companies. Potentially, the information could be a factor in variety if business decisions, including level of pricing or supply for bikes in different seasons.   

Considering these possible applications, this report will attempt to answer: **To what extent can weather data predict the number of bike rentals in different parts of the day?** Weather data is understood in terms of temperature, wind speed, humidity and occurrence of weather phenomena (including storms, snow and rain). 

---
# Dataset
The dataset was retrieved from the open-source machine learning repository [UC Irvine](https://archive.ics.uci.edu/dataset/275/bike+sharing+dataset) and Hadi Fanaee-T from the Laboratory of Artificial Intelligence and Decision Support (LIAAD), University of Porto is credited as its author. The bike rentals data originates from the Capital Bikeshare company based in Washington DC, United States. The dataset contains the hourly and daily counts of bike rentals and weather data in the years 2011 and 2012 in the American capital. We opted to use the hourly data due for modeling, due to the larger sample size (the dataset consists of 17379 data points) and less aggregated data. We found the smaller degree of aggregation important, as weather can change drastically throughout a 24 hour period. In case of further interest or replication of our research analysis, you can trace the link to this dataset at the end of this paper in our [References](#ref)

# Loading data

The repository provided us with three files, namely:  

* `hour.csv`, hourly data of bike rentals.
* `day.csv`, daily data of bike rentals.
* `README.txt`, providing additional metadata about the file and their data.

We first specify our dependencies and read the data from `hour.csv`. We also load `day.csv`, solely for comparison purposes in our [EDA](#eda) phase.  

```{r import dependencies, message = FALSE}
library(tidyverse)
library(fastDummies)
library(kableExtra)
library(gridExtra, exclude="combine")
library(lubridate)
library(car)
library(ICC)
library(caret)
```

```{r read data  files}
# Source hourly data for model
source_data <- read.csv("../data/hour.csv", header = TRUE, sep = ",") %>%
  as_tibble()

# Extra daily data for EDA
day_df <- read.csv("../data/hour.csv", header = TRUE, sep = ",") %>%
  as_tibble()

# Clone source
data <- source_data

head(data)
```

We then create a sub-selection of variables that are of interest for our model; these are the control, predictor and outcome variables, as well as, variables necessary for EDA and preprocessing.

```{r variable selection}
data <- select(data,
               dteday,
               hr,
               workingday,
               weathersit, 
               temp, 
               atemp, 
               hum, 
               windspeed, 
               casual,
               registered,
               cnt)
```

## Variables description {#vardesc}

```{r variabe table, echo=FALSE}
# creating a table describing the variables used
variables <- read.csv("../data/variables2.csv", header = TRUE, sep = ";")%>%
  as_tibble()
variables <- variables[1:11, 1:5]

variables %>% 
  kable()%>%
  kable_styling()
```
The table above does not contain a raw outcome variable as of yet. Rather, three variables - namely `casual`, `registered` and `cnt` - are components that will be utilised when creating our outcome variable later on.

The categories of `weathersit` represent the following weather phenomena and their combinations:

1.    Clear, Few clouds, Partly cloudy, Partly cloudy
2.    Mist and Cloudy, Mist and Broken clouds, Mist and Few clouds, Mist
3.    Light Snow, Light Rain and Thunderstorm and Scattered clouds, Light Rain and Scattered clouds
4.    Heavy Rain and Ice Pallets and Thunderstorm and Mist, Snow and Fog


# Preprocessing & EDA {#eda}

## Type checking
Some of our categorical variables (i.e. `workingday`, `weathersit`, `hr`) are interpreted as integers rather than factors. We transform these data to factors for ease of processing and modeling.

```{r transform types}
data <- data %>%
  mutate(
    workingday = as.factor(workingday),
    weathersit = as.factor(weathersit),
    hr = as.factor(hr)
  )
```

## Creating Additional Variables {.tabset}
We decided that including a time component in our final model is essential. Night hours are approximately half of the data and are characterized by much lower rental counts than the daylight values. Without separating the night data the predictors we expected the predicted rentals during the more active periods to be underestimated. However, we are interested in modeling rental values for the entire day. Thus, we do want to include the hours as a categorical predictor to be able to control the night and day periods. 

However, 24 dummy codes is too much for substantive interpretation. Thus, we decided to aggregate the hourly data into 3 day segments night (23-6), morning-noon(7-14) and eve (15-22). The decision to divide into these categories was made by looking at the distribution of the rental counts at specific hours. We noticed a natural division into these 3 segments. Dividing the time in these periods would potentially solve the problem of interpreting dummy encodings and clusters of  low-night and high-day rentals being incorrectly estimated.

This section describes the process of creating new variables that will be later used to aggregate the data into segments. The aggregation process is described in [Data Aggregation](#agg).

### Create outcome variable
By combining the component outcome variables mentioned in [Variable description](#vardesc), we create `registered_prop`, which is the proportion subscribed rentals of the total rental count. Consequently, we use the mean of this variable to create a binary outcome variable called `more_registered`.

```{r create outcome variable}
# Create binary variable, returning true if proportion is higher than respective mean.
create_ouctome <- function(prop, mean) {
    ifelse(prop > mean, 1, 0) %>%
    as.factor()
}

# Bind binary variable to data.
data <- data %>%
  mutate(
    registered_prop = registered / cnt,
    more_registered = create_ouctome(registered_prop, mean(registered_prop))
  )

# Inspect data.
head(data)

prop_mean = mean(data$registered_prop)
```

### Expand `dteday` data
We  create a new variable `dt_num` that provides a numeric value that represents an identifier that maps an hourly based entry to a day ID $[1..7]$. We create it by converting the `dteday` variable.

```{r date expansion}
# Converts datetime string to numeric with origin offset.
date_to_num <- function(date, offset) {
   as.integer(as.Date(date, "%Y-%m-%d")) - offset
}

# Fetch origin.
dt_offset <- source_data$dteday[1] %>%
  date_to_num(0) - 1


data <- data %>%
  mutate(
    dt_num = date_to_num(dteday, dt_offset)
  )

# Global variable for amount of unique days.
n_days <- n_distinct(data$dteday)
```

## Descriptive Statistics

We obtained the descriptive statistics of our variables. 

```{r summarise data, echo=FALSE}
summary(data)
```

The most important information we obtained here is that the data contains `r n_days` unique days, meaning that the entirety of 2011 (365 days) and 2012 (366 days) was recorded. However, we note that there is approximately 100 less "night" hours in the dataset than the other two segments suggesting there might be some missing records.  

## Distributions {#dists}

Since the summaries are not giving a precise enough picture, we histograms of the variables.

```{r distributions, echo=FALSE, message=FALSE}
grid.arrange(
    ggplot(data, aes(cnt)) + geom_histogram() + labs (x = "Number of bike rentals",
          y = "Frequency") + theme_bw(),
    ggplot(source_data, aes(temp)) + geom_histogram() + labs (x = "Temperature",
          y = "Frequency")+ theme_bw(),
    ggplot(data, aes(atemp)) + geom_histogram() + labs (x = "Feeling temperature",
          y = "Frequency")+ theme_bw(),
    ggplot(data, aes(hum)) + geom_histogram() + labs (x = "Humidity",
          y = "Frequency")+ theme_bw(),
    ggplot(data, aes(windspeed)) + geom_histogram() + labs (x = "Wind speed",
          y = "Frequency")+ theme_bw()
)
```

The histogram of number of bike rental reveals that lower numbers of rentals are much more frequent, with no (or little to no) bikes being rented being the most frequent state. Based on the graph used to create day segments, we are fairly certain that this distribution would look differently per `hr_seg` cluster and that the majority of the low number of rentals occur in the night. 

The hour graph confirms the missing records in some `hr` categories. We suspect that this could be caused by data cleaning from the author of the dataset, since the night hours are likely to have no rentals. Alternatively, maybe the bike rental company was not operating during those low traffic hours for reasons that could include lack of night workers or updates in the system. Lastly, we considered time changes, however, those would only impact the records of one of the hours. Nevertheless, the difference should not impact the final results of our analysis. 

The weather phenomena histograms reveals that the 4th category, the harshest weather phenomena, is barely present. If we use it in our model, the category would be a categorical outlier and needs to be addressed. 

The distribution of temperature and feeling temperature is quite normal. However, both humidity and wind speed have a number of `0` values that are disjointed from the rest of the data. They may constitute possible outliers and we will look at them closer in the next section. 

## Outliers {.tabset}

Since there was an indication of outliers, we decided to detect them using quantiles. We made the following box plots:  
```{r boxplots, echo=FALSE, message=FALSE}
grid.arrange(
    ggplot(data, aes(temp)) + geom_boxplot() + labs (x = "Temperature") + theme_bw(),
    ggplot(data, aes(atemp)) + geom_boxplot() + labs (x = "Feeling temperature") + theme_bw(),
    ggplot(data, aes(hum)) + geom_boxplot() + labs (x = "Humidity") + theme_bw(),
    ggplot(data, aes(windspeed)) + geom_boxplot() + labs (x = "Wind speed") + theme_bw(),
    ggplot(data, aes(cnt)) + geom_boxplot() + labs (x = "Number of bike rentals") + theme_bw()
)
```

The box plots further support our observations from earlier. Temperature and feeling temperature are distributed very normally and display no outliers on the box plots. Humidity has a a few `0` values that are flagged as outliers. In the wind speed, the large number of `0` values skews the distribution towards the smaller values, leaving a lot of the high wind speeds as outliers. The box plot of number of bike rentals reveals a large number of outliers in our outcome variable. We already observed that the night hours are dominated by small rental number, thus skewing the distribution to the left and leaving the high rental values as outliers. 

We investigate the "problematic" variables: humidity, wind speed and number of rentals, further below:

### Rental count outliers

Since we suspect that a large amount of rentals' outliers is due to low rental count during the night, we decided to make separate histogram and boxplot graphs for the three day segments.  
```{r distributions rental count, echo=FALSE, message=FALSE}
ggplot(data, aes(cnt)) + geom_histogram() + labs (x = "Number of bike rentals",  title = "Distribution of bike rentals throughout the day segments")+ theme_bw()
```

In the histogram we see the drastically different night distribution to the other two day segments, with the frequency of small numbers of rentals dominating the entire data. However, all three distributions are quite positively-skewed even after the division  into the time segments. 

```{r boxplots rental count, echo=FALSE, message=FALSE}
ggplot(data, aes(cnt)) + geom_boxplot() + labs (x = "Number of bike rentals",  title = "Boxplot of bike rentals, seperated by the day segments")+ theme_bw()
```

The right-skewed distributions throughout the segments are visible in the boxplots. That is why dividing the boxplot according to the time segments still results in outliers at the tail-end of the values. However, the outlier values are quite reasonable. It is realistic for the rental company to be far more likely to receive  smaller number of rentals and not operating at their full capacity. Hence the outliers remain in the dataset.

### Windspeed outliers

The distribution of wind speed is right-skewed, hence large values are seen as outliers. We do note the presence of gap between `0` values and the first non-zero values, specifically:  
```{r windspeed value frequencies}
data %>%
  group_by(windspeed) %>%
  summarise(n = n()) %>%
  arrange(windspeed) %>%
  head()
```

While the `0.00` values fall within the distribution, it is only odd that there's a small increment between the `0.00` occurrences and the values thereafter (e.g. `0.0869`).
This might be due to sensor threshold for measuring wind speed or these might also be possible missing values which were replaced with `0.00`. Since we cannot know for certain and the number of occurrences for `0.00` is in line with neigbouring values, we choose to keep them.

### Humidity outliers

A similar gap between `0.00` values and the next non-zero value occurs in the humidity variable: 
```{r humidity value frequencies}
data %>%
  group_by(hum) %>%
  summarise(n = n()) %>%
  arrange(hum) %>%
  head()
```

In fact, there are 22 hours in which the value is registered. Humidity of `0.00` is not possible in nature, which suggests that the values might be a mistake or a missing value. However, the values have been normalized and we do not know the specific method used. Thus, there is a significant possibility that the value `0.00` does not represent a true `0.00` humidity and is just the minimal value in the data. Since the number of these outliers is small and they could be real data, we chose to keep them.

### Weathersit outliers
Remove category 4.
```{r weathersit 4 removal}
data <- data %>%
  filter(weathersit != 4)
```

## Missing data

The dataset's source claimed there is no missing data. We verified that, by checking if any standard NA values are present.

```{r missing standard}
anyNA(data)
```

There is no standard missing data. There is no missing data in general under any other name. 

### Missing records for hour

As mentioned before the only type of missing data is the fact that our dataset is not complete in terms of containing all the hours of the two years. Some `hr` values seem to have a lower amount of occurrences than others, as can be seen below:

```{r number of missing entries, echo=FALSE}

# Count the amount of records per hour.
# Also add a column for amount of *missing* records.
hr_df <- data %>%
  group_by(hr) %>%
  summarise(
    n = n(),
    n_missing_days = n_days - n) # using global variable `n_days`.

ggplot(hr_df, aes(hr, n_missing_days)) +
  geom_bar(stat = "identity")+
  labs (x = "hour, with 0 representing 1 am",
        y =  "Number of missing records",
        title = "Distribution of missing hours")+
  theme_bw()
```

Thus, most of the missing hours are between 3am and 6am. The lack of records during the night could be potentically caused by maintenance conducted by the rental company at those hours, time changes or shortage of night workers. To investigate further we decided to see during which days are the missing hours present: 

*Table showing days with the highest number of missing records*
```{r index of missing entries, message = FALSE, echo=FALSE}
# Create dataframe with amount of missing records per day.
missing_df <- data %>%
  group_by(dteday, dt_num) %>%
  summarise(
    n_records = n(),
    n_missing_records = 24 - n_records
  ) %>%
  filter(n_missing_records > 0) %>%
  arrange(desc(n_missing_records)) %>%
  select(dteday, n_missing_records)

# `n_missing_records` is the amount of missing entries on that particular day.

head(missing_df, 10)
```

The majority of the missing records seems to be concentrated on just four days. Particularly, on the `2012-10-29` and `2012-10-30` the records are missing for 36 consecutive hours, which suggests a system outage of the rental company or another similar disturbance to the measurement of the data. Since the number of missing records is small compared to the size of the dataset, we do not think they will impact our analysis.

## Relations
```{r predictor vs. outcome}
ggplot(data, aes(workingday)) +
  geom_bar(aes(fill = workingday))

ggplot(data, aes(hum)) +
  geom_histogram(aes(fill = workingday)) +
  facet_wrap(~ workingday)

ggplot(data, aes(temp)) +
  geom_histogram(aes(fill = workingday)) +
  facet_wrap(~ workingday)

ggplot(data, aes(windspeed)) +
  geom_histogram(aes(fill = workingday)) +
  facet_wrap(~ workingday)

ggplot(data, aes(weathersit)) +
  geom_bar(aes(fill = workingday)) +
  facet_wrap(~ workingday)
```

# Model creation & comparison
```{r model creation}
model1 <- glm(more_registered ~ workingday, family = binomial, data)
model2 <- glm(more_registered ~ workingday + temp, family = binomial, data)
model3 <- glm(more_registered ~ workingday + temp + hum, family = binomial, data)
model4 <- glm(more_registered ~ workingday + temp + hum + windspeed, family = binomial, data)
model5 <- glm(more_registered ~ workingday + temp + hum + windspeed + weathersit, family = binomial, data)
model6 <- glm(more_registered ~ workingday*(windspeed + temp + hum) + weathersit, family = binomial, data)
```

```{r model comparison}
comp_df <- data.frame(
  model = c('model1', 'model2', 'model3', 'model4', 'model5', 'model6'),
  predictors = c('workingday', 'workingday + temp', 'workingday + temp + hum', 'workingday + temp + hum + windspeed', 'workingday + temp + hum + windspeed + weathersit', 'workingday + temp + hum + windspeed + weathersit'),
  moderator = c('', '', '', '', '', 'workingday'),
  AIC = c(AIC(model1), AIC(model2), AIC(model3), AIC(model4), AIC(model5), AIC(model6)),
  BIC = c(BIC(model1), BIC(model2), BIC(model3), BIC(model4), BIC(model5), BIC(model6))
)

comp_df
```

# Assumptions
## Full-rank predictor matrix

```{r}
vif(model5)
vif(model6, type = 'predictor')
```
Working day as a moderator seems to be CRINGE. We want no CRINGE. Begone, working day (moderator). From now on, we will be working with model5.

## Data transformation
Apply mean-centering as a default for introducing possible interaction terms.

Mean centering does not influence interaction term, neither does it change the model statistics [@mean]
```{r apply mean-centering}
# Mean-centers the data without applying scaling.
center_scale <- function(x) {
    scale(x, scale = FALSE)
}

# Transform the data.
data <- data %>%
  mutate(across(where(is.numeric), center_scale))
```

## Remodelling
```{r remodel creation}
model1 <- glm(more_registered ~ workingday, family = binomial, data)
model2 <- glm(more_registered ~ workingday + temp, family = binomial, data)
model3 <- glm(more_registered ~ workingday + temp + hum, family = binomial, data)
model4 <- glm(more_registered ~ workingday + temp + hum + windspeed, family = binomial, data)
model5 <- glm(more_registered ~ workingday + temp + hum + windspeed + weathersit, family = binomial, data)
model6 <- glm(more_registered ~ workingday*(windspeed + temp + hum) + weathersit, family = binomial, data)
```

```{r remodel comparison}
comp_df <- data.frame(
  model = c('model1', 'model2', 'model3', 'model4', 'model5', 'model6'),
  predictors = c('workingday', 'workingday + temp', 'workingday + temp + hum', 'workingday + temp + hum + windspeed', 'workingday + temp + hum + windspeed + weathersit', 'workingday + temp + hum + windspeed + weathersit'),
  moderator = c('', '', '', '', '', 'workingday'),
  AIC = c(AIC(model1), AIC(model2), AIC(model3), AIC(model4), AIC(model5), AIC(model6)),
  BIC = c(BIC(model1), BIC(model2), BIC(model3), BIC(model4), BIC(model5), BIC(model6))
)

comp_df
```

## Binary dependent variable & balanced outcomes
Check whether the outcome variable is binary. Moreover, the minority and majority class should be somewhat balanced.
```{r check binary outcome}
data %>%
  count(more_registered) %>%
  mutate(prop = round(n / sum(n), 2))
```

## Sufficient sample size
Using the proportion of the minority class, obtained from previous table, we can calculate the minimal amount of positive cases necessary for this assumption to hold.
```{r check sample size}
minimum_positive_cases <- function(k, p) {
  round((10 * k) / p)
}

minimum_positive_cases(4, 0.43)
```


## Continuous predictors are linearly related to the logit(π)

```{r}
data$logit <- predict(model5, type = "link")

data %>%
  ggplot(aes(temp, logit)) +
  geom_point() +
  geom_smooth(method = "glm")

data %>%
  ggplot(aes(hum, logit)) +
  geom_point() +
  geom_smooth(method = "glm")

data %>%
  ggplot(aes(windspeed, logit)) +
  geom_point() +
  geom_smooth(method = "glm")
```


## Influential schmimfluential

```{r}
plot(model5, which = c(4, 5))
```

## Deviance residuals

```{r}
dr <- resid(model5, type = "deviance")

eta <- predict(model5, type = "link")

dr_data <- data.frame(residuals = dr, eta = eta)

ggplot(dr_data, aes(x = eta, y = residuals)) +
  geom_point() +
  geom_smooth(se = FALSE, method = "glm")

plot(model5, which = 1)
```

# Interpretation of final model

Based on the model comparision earlier, we chose model 6, which is represented by the following formula:$$
    logit(\hat{\pi}) = \hat{\beta_0} +  \hat{\beta_1}workingday + \hat{\beta_2} windspeed + \hat{\beta_3} temp + \hat{\beta_4} hum + \hat{\beta_5} workingday * windspeed + $$
    $$ +\hat{\beta_6} whethersit2 + \hat{\beta_7}whethersit3 + \hat{\beta_8} workingday * temp + \hat{\beta_9} workingday * hum
    $$

## Quality of the model

```{r}
summary(model6)
```

Interpret: 
- is the model significant
- is each predictor significant + interpretation of it's effect

Quality of the model - ROC curve

## Classification Performance

For classification purposes use a threshold of 0.5, as in if the probability of the proportion of registered users is higher than average is 50% then the case is classified as a "success". We decided to use the standard 0.5 threshold because we did not find any substantial reason to justifying changing it to a different value. 

```{r confusion matrix}
# to create a confusion matrix we require a variable that informs us if the model classifies a given 
data <- data %>%
mutate(piHat = predict(model6, type = "response"),
yHat = as.factor(ifelse(piHat <= 0.5, "0", "1"))
)

#creating the confusion matrix 
cMat <- confusionMatrix(data = data$yHat, reference = data$more_registered)
cMat$table

# extracting the Accuracy and other classification statistics for the overall model
cMat$overall 
# extracting the Accuracy and other classification statistics for Positive and Negative prediction
cMat$byClass

```
### Summary of the confusion matrix
Based on the output above we find the following characteristics of our model: 
```{r table_prediction_statistics, echo = FALSE}

# We decided to present the most important predicting characteristics of our model (Accuracy, Sensitivity etc) in a form of a table. This code creates this table

summary_confmatrix <- data.frame(
  Measure = c('Accuracy', 'Error Rate', 'Sensitivity', 'Specificity', 'False Positive Rate', 'Positive Predictive Value', 'Negative Predictive Value'),
  Value = c(round(cMat$overall[1], digits = 3), round((1585 + 2988)/ ( 1585 + 2988 + 4509 + 8297), digits = 3), round(cMat$byClass[1], digits = 3), round(cMat$byClass[2], digits = 3), round(2988 / (5409 + 2988), digits = 3), round(8297 / (8297 + 2988), digits = 3), round(5409 / (5409 + 1585), digits = 3)),
  Interpretation = c('% correctly classified', '% incorrectly classified', '% of cases with registered rentals ratio being above average that are correctly classified', '% of cases with registered rentals ratio being below average that are correctly classified', '% of  cases with registered rentals ratio being below are incorrectly classified as more than average', '% chance that a case classified as above average was classified correctly', '% chance that a case classified as below average was classified correctly'),
  Formula = c('(TP + TN)/ (P + N)', '(FP + FN)/ (P + N)', 'TP / (TP + FN)', 'TN / (TN + FP)', 'FP / (TN + FP)', 'TP / (TP + FP)', 'TN / (TN + FN)')
)

summary_confmatrix %>% 
  kable()%>%
  kable_styling()
```


## Intercept

## Significance of predictors

## Interpretation of coefficents 
- invert the coefficents to exponential

## Answering the research question


# References {#ref}

<div id="refs"></div>

