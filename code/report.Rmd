---
title: "Bike Sharing"
author: "Aga, Karla, Nisse, Ole"
date: "`r Sys.Date()`"
output: 
  html_document:
    theme: united
    number_sections: false
    toc: true
    toc_float:
      collapsed: true
    df_print: paged
bibliography: references.bib  
---

<style>
body {
text-align: justify}
</style>

# Abstract
![](../images/bike_sharing.jpeg)  

"*Bikesharing contributes to the advent of more sustainable transportation in cities around the globe.*" [@beland]. Bikesharing programs are designed to provide short-term bicycle rental in stations dispersed throughout the cities and located near public transportation hubs [@beland]. They have numerous environmental and health benefits, such as reducing congestion, complementing other forms of public transportation and encouraging exercise [@beland]. Additionally, accessible bike rental has a lower barrier of entry than purchasing your own bike and is more convenient for out-of-town commuters.  

In principle bicycles pose a good substitute for car use in urban areas, however, they have certain limitations. Among them is the exposure of cyclists to weather while commuting compared to other means of transportation. It would be intuitive for the number of bike rentals to be dependent on current weather conditions. If that is the case, the extent of that relationship would be important information for the bikesharing companies. Potentially, the information could be a factor in variety if business decisions, including level of pricing or supply for bikes in different seasons.   

Considering these possible applications, this report will attempt to answer: **To what extent can weather data predict the number of bike rentals in different parts of the day?** Weather data is understood in terms of temperature, wind speed, humidity and occurrence of weather phenomena (including storms, snow and rain). 

---
# Dataset
The dataset was retrieved from the open-source machine learning repository [UC Irvine](https://archive.ics.uci.edu/dataset/275/bike+sharing+dataset) and Hadi Fanaee-T from the Laboratory of Artificial Intelligence and Decision Support (LIAAD), University of Porto is credited as its autheor. The bike rentals data originates from the Capital Bikeshare company based in Washington DC, United States. The dataset containes the hourly and daily counts of bike rentals and weather data in the years 2011 and 2012 in the American capital. We opted to use the hourly data due for modeling, due to the larger sample size (the dataset consists of 17379 data points) and less aggregated data. We found the smaller degree of aggregation important, as weather can change drastically throughout a 24 hour period. In case of further interest or replication of our research analysis, you can trace the link to this dataset at the end of this paper in our “References.” 

# Loading data

The repository provided us with three files, namely:  

* `hour.csv`, hourly data of bike rentals.
* `day.csv`, daily data of bike rentals.
* `README.txt`, providing additional metadata about the file and their data.

We first specify our dependencies and read the data from `hour.csv`. We also load `day.csv`, solely for comparison purposes in our [EDA](#eda) phase.  

```{r import, message = FALSE}
library(tidyverse)
library(fastDummies)
library(kableExtra)
library(gridExtra, exclude="combine")
library(lubridate)
library(car)
library(ICC)
```

```{r read bike}
# Source hourly data for model
source_data <- read.csv("../data/hour.csv", header = TRUE, sep = ",") %>%
  as_tibble()

# Extra daily data for EDA
day_df <- read.csv("../data/hour.csv", header = TRUE, sep = ",") %>%
  as_tibble()

# Clone source
data <- source_data

head(data)
```

We then create a sub-selection of variables that are of interest for our model; these are the control, predictor and outcome variables, as well as, variables necessary for EDA and preprocessing.

```{r select}
data <- select(data,
               dteday,
               hr, 
               weathersit, 
               temp, 
               atemp, 
               hum, 
               windspeed, 
               cnt)
```

## Variables description  

```{r var_table, echo=FALSE}
# creating a table describing the variables used
variables <- read.csv("../data/variables2.csv", header = TRUE, sep = ";")%>%
  as_tibble()
variables <- variables[1:8, 1:5]

variables %>% 
  kable()%>%
  kable_styling()

```

The categories of 'weathersit' represent the following weather phenomena and their combinations:

1.    Clear, Few clouds, Partly cloudy, Partly cloudy
2.    Mist and Cloudy, Mist and Broken clouds, Mist and Few clouds, Mist
3.    Light Snow, Light Rain and Thunderstorm and Scattered clouds, Light Rain and Scattered clouds
4.    Heavy Rain and Ice Pallets and Thunderstorm and Mist, Snow and Fog


# Preprocessing & EDA {#eda}

## Creating Additional Variables {.tabset}
We decided that including a time component in our final model is essential. Night hours are approximately half of the data and are characterized by much lower rental counts than the daylight values. Without separating the night data the predictors we expected the predicted rentals during the more active periods to be underestimated. However, we are interested in modeling rental values for the entire day. Thus, we do want to include the hours as a categorical predictor to be able to control the night and day periods. 

However, 24 dummy codes is too much for substantive interpretation. Thus, we decided to aggregate the hourly data into 3 day segments night (23-6), morning-noon(7-14) and eve (15-22). The decision to divide into these categories was made by looking at the distribution of the rental counts at specific hours. We noticed a natural division into these 3 segments. Dividing the time in these periods would potentially solve the problem of interpreting dummy encodings and clusters of  low-night and high-day rentals being incorrectly estimated.

This section describes the process of creating new variables that will be later used to agrregate the data into segments. The aggregation process is described in [Data Aggregation](#agg).

### Expand `dteday` data
We  create a new variable 'dt_num' that provides a numeric value that represents to which out of the 731 days in the dataset a given hourly data point belongs. We create it by converting the `dteday` variable.

```{r expand date}
# Converts datetime string to numeric with origin offset.
date_to_num <- function(date, offset) {
   as.integer(as.Date(date, "%Y-%m-%d")) - offset
}

# Fetch origin.
dt_offset <- source_data$dteday[1] %>%
  date_to_num(0) - 1


data <- data %>%
  mutate(
    dt_num = date_to_num(dteday, dt_offset)
  )

# Global variable for amount of unique days.
n_days <- n_distinct(data$dteday)
```

### Clustering of `hr` categories {#clus}
We create a new variable 'hr_seg' that gives each data point with an hour within our giver segment the name of that segment. 
```{r hour cut}
# Shift the `hr` data by 2 and increment the hour 23 for easier binning via the cut function.
data <- data %>%
  mutate(hr_idx = hr + 2)

data$hr_idx[data$hr == 23] <- 1

# Cut the 24 hour entries in 3 categories.
data <- data %>%
  mutate(hr_seg = cut(
    hr_idx,
    breaks = c(0, 8, 16, 24),
    labels = c("night", "morning-noon", "eve")
  ))
```

After creating the categories, we check whether segmenting of `hr` was applied correctly by looking at single day data:

```{r bin check}
# Check output for single day.
data %>%
  filter(dteday == "2011-01-01") %>%
  arrange(hr) %>%
  select(hr, hr_seg) %>%
  head(24)
```

The segments were chosen based on distribution of rental counts in given hours. Additionally, we wanted the segments to be of equal size to ensure all hours are equally represented in the model. Below we present one of the graphs we used to make the decision. 

```{r determine segment, message=FALSE, echo=FALSE}

# Plot hr~cnt with current segmentation indicator.
data %>%
  group_by(hr, hr_seg) %>%
  summarise(
    cnt = sum(cnt)
  ) %>%
  ggplot(aes(hr, cnt, fill = hr_seg)) +
    geom_bar(stat = "identity")+
    labs (x = "Hour, where 0 reprenents 1 am",
          y = "Sum of all rentals at that hour in 2011 and 2012",
          title = "Distribution of bike rentals throughout the day")+
  theme_bw()
```

## Descriptive Statistics

We obtained the descriptive statistics of our variables. 

```{r summary, echo=FALSE}
summary(data)
```

The most important information we obtained here is that the data contains `r n_days` unique days, meaning that the entirety of 2011 (365 days) and 2012 (366 days) was recorded. However, we note that there is approximately 100 less "night" hours in the dataset than the other two segments suggesting there might be some missing records.  

## Distributions {#dists}

Since the summaries are not giving a precise enough picture, we histograms of the variables.

```{r distributions, echo=FALSE, message=FALSE}
grid.arrange(
      ggplot(data, aes(cnt)) + geom_histogram() +labs (x = "number of bike rentals",
          y = "frequency")+ theme_bw(),
    ggplot(data, aes(hr)) + geom_histogram(binwidth = 1) + labs (x = "hour",
          y = "frequency")+ theme_bw(),
    ggplot(data, aes(weathersit)) + geom_histogram(binwidth = 1) + labs (x = "weather phenomena", y = "frequency")+ theme_bw(),
    ggplot(data, aes(temp)) + geom_histogram() + labs (x = "temperature",
          y = "frequency")+ theme_bw(),
    ggplot(data, aes(atemp)) + geom_histogram() + labs (x = "feeling temperature",
          y = "frequency")+ theme_bw(),
    ggplot(data, aes(hum)) + geom_histogram() + labs (x = "humidity",
          y = "frequency")+ theme_bw(),
    ggplot(data, aes(windspeed)) + geom_histogram() + labs (x = "wind speed",
          y = "frequency")+ theme_bw()
)
```

The histogram of number of bike rental reveals that lower numbers of rentals are much more frequent, with no (or little to no) bikes being rented being the most frequent state. Based on the graph used to create day segments, we are fairly certrain that this distribution would look differently for the different segments and majority of the low number of rentals occur in the night. 

The hour graph confirms the missing records in some `hr` categories. We suspect that this could be caused by data cleaning of the author of the dataset, since the night hours are likely to have no rentals. Alternatively, maybe the bike rental company was not operating during those low traffic hours for reasons that could include lack of night workers or updates in the system. Lastly, we considered time changes, however, those would only impact the records of one of the hours. Nevertheless, the difference should not impact the final results of our analysis. 

The weather phenomena histograms reveals that the 4th category, the harshest weather phenomena, is barely present. If we use it in our model the category would be a categorical outlier and needs to be addressed. 

The distribution of temperature and feeling temperature is quite normal. However, both humidity and wind speed have a number of "0" values that are disjointed from the rest of the data. They may constitute possible outliers and we will look at them closer in the next section. 

## Outliers {.tabset}

Outlier detection using quantiles.  
```{r outliers, echo=FALSE, message=FALSE}
grid.arrange(
    ggplot(data, aes(temp)) + geom_boxplot(),
    ggplot(data, aes(atemp)) + geom_boxplot(),
    ggplot(data, aes(hum)) + geom_boxplot(),
    ggplot(data, aes(windspeed)) + geom_boxplot(),
    ggplot(data, aes(cnt)) + geom_boxplot()
)
```

Notice the following:

-   Large amount of outliers in `cnt` (outcome variables (due to right-skewed distr).
-   Some outliers in `windspeed`.
-   3x `0.00` values of `hum`.
The 

### Rental count outliers
Large amount of `cnt` outliers is due to low rental count during the night, which shifts the median to a lower value. `hr_seg` acts as moderator, so better to check data displays *per* `hr_seg` cluster.  

```{r cnt outliers, echo=FALSE, message=FALSE}
ggplot(data, aes(cnt, colour = hr_seg)) + geom_boxplot()

ggplot(data, aes(cnt)) + geom_histogram() + facet_wrap(vars(hr_seg))
```

Even then we see that distributions per `hr_seq` are heavily right-skewed, explaining the multitude of outliers.  
Looking at the tail-end of the `cnt` values, these seem to be non-error outliers. Furthermore they seem to be reasonable values due to right-skewness, hence we don't remove them.

### Windspeed outliers

Again right-skewed, hence large values are seen as outliers. Do notice how there's gap between 0 values and the first non-zero values, specifically:  
```{r windspeed outliers}
data %>%
  group_by(windspeed) %>%
  summarise(n = n()) %>%
  arrange(windspeed) %>%
  head()
```

Might be due to sensor threshold for measuring windspeed. In any case, these values fall within the distribution, it is only odd that there's a small increment between the `0.00` occurences and the values thereafter (e.g. `0.0869`).
These might also be possible missing values which are replaced with `0.00`.  
In any case, we cannot know for certain. Since the number of occurrences for `0.00` is in line with neigbouring values, we choose to keep them.

### Humidity outliers

`hum` is left-skewed.
```{r hum outliers}
data %>%
  group_by(hum) %>%
  summarise(n = n()) %>%
  arrange(hum) %>%
  head()
```


```{r}
# Code for removing the outliers that we think are here because of a mistake?
```

## Missing data

Check standard NA values. There are none.

```{r missing standard}
anyNA(data)
```

### Missing records for hour

Some `hr` values seem to have a lower amount of occurrences than others, as can be seen in distribution plot of [Distributions](#dists)

```{r hr missing}
# Count the amount of records per hour.
# Also add a column for amount of *missing* records.
hr_df <- data %>%
  group_by(hr) %>%
  summarise(
    n = n(),
    n_missing_days = n_days - n) # using global variable `n_days`.

ggplot(hr_df, aes(hr, n_missing_days)) +
  geom_bar(stat = "identity")
```

Determine where missing records are located. Seems that a system outtage (or the like) was present on `2012-10-29` and `2012-10-30`, with a combined total of `35` missing records.
```{r missing location, message = FALSE}
# Create dataframe with amount of missing records per day.
missing_df <- data %>%
  group_by(dteday, dt_num) %>%
  summarise(
    n_records = n(),
    n_missing_records = 24 - n_records
  ) %>%
  filter(n_missing_records > 0) %>%
  arrange(desc(n_missing_records)) %>%
  select(dteday, n_missing_records)

head(missing_df, 10)
```

`n_missing_records` is the amount of missing entries on that particalur day.

## Covariance {.tabset}

### Covariance with predictor `atemp`

Have suspicion that `atemp` might be correlated with `temp`, `windspeed` and `hum`, since it is a combined variable of the three (mayhaps). Justify this:

```{r atemp covar, echo=FALSE}
grid.arrange(
  ggplot(data, aes(temp, atemp)) + geom_point(),
  ggplot(data, aes(windspeed, atemp)) + geom_point(),
  ggplot(data, aes(hum, atemp)) + geom_point(),
  nrow = 1
)
```

Can conclude that predictor variables `atemp` and `temp` are heavily correlated, whilst `hum` and `windspeed` have a weaker relation with `atemp`.

### Covariance with outcome variable `cnt`

Remark:  

- Non-linear relation between `hum` and `cnt`
- Negative relation between `windspeed` and `cnt`
- Positive relation between `temp` and `cnt`, up until high temperatures are reached (ppl dont like biking in hot water, don't blame them).

```{r cnt covar, echo=FALSE}
plot_cnt_covar <- function(plot) (
  plot
    + geom_point() 
    + geom_smooth(method = 'loess') 
    + facet_wrap(vars(hr_seg))
)

ggplot(data, aes(temp, cnt)) %>% plot_cnt_covar()
ggplot(data, aes(windspeed, cnt)) %>% plot_cnt_covar()
ggplot(data, aes(hum, cnt)) %>% plot_cnt_covar()

```

## Data Aggregation {#agg}
After having created `hr_seq`, we aggregate the data based on both the date (`dteday`) and the hour segments (`hr_seg`. In case of dichotomous variables, we take the `mode` of the variable, with earlier defined function.
```{r aggregate hour, message=FALSE}
# Create a `mode` function for aggregation.
mode <- function(x) {
    which.max(table(x))
}

# Aggregate over `hr_bin` factor.
data <- data %>%
    group_by(dteday, hr_seg) %>%
    summarize(
        temp = mean(temp),
        atemp = mean(atemp),
        hum = mean(hum),
        windspeed = mean(atemp),
        weathersit = mode(weathersit),
        cnt = sum(cnt)
    )
```




# Model creation & comparison

Later on in [Assumptions](#assum) we concluded a non-linear (higher-order) relation between `hum` and `cnt`. To approximate a linear relation, we've transformed the data to `f(x) = x^3`, saved in column `hum3`.  

```{r solve non lin}
data$hum3 = data$hum^3
```

Create simple and complex models. Order is based on covariance table (high to low).
```{r model creation}
# Create models.
model1        <- lm(cnt ~ temp, data)
model2        <- lm(cnt ~ temp + hum3, data)
model3        <- lm(cnt ~ temp + hum3 + weathersit, data)
model4        <- lm(cnt ~ temp + hum3 + weathersit + windspeed, data)

# Include moderator for model of choice (#2), for comparison analysis.
model2_mod    <- lm(cnt ~ (temp + hum3)* hr_seg, data)
```

Comparison results table.
```{r comparison}
RMSE <- function(model) {
  model$residuals^2 %>% mean()
}

comp_df <- data.frame(
  model = c('model1', 'model2', 'model3', 'model4', 'model2_mod'),
  predictors = c('temp', 'temp + hum3', 'temp + hum3 + weathersit', 'temp + hum3 + weathersit + windspeed', 'temp + hum3'),
  moderator = c('', '', '', '', 'hr_seg'),
  AIC = c(AIC(model1), AIC(model2), AIC(model3), AIC(model4), AIC(model2_mod)),
  BIC = c(BIC(model1), BIC(model2), BIC(model3), BIC(model4), BIC(model2_mod)),
  RMSE = c(RMSE(model1), RMSE(model2), RMSE(model3), RMSE(model4), RMSE(model2_mod))
)


comp_df
```

Anova tests.
```{r anovas}
# Simple and complex model
anova(model1, model2)
anova(model2, model3)
anova(model3, model4)

# Test addition of moderator
anova(model2, model2_mod)
```

# Assumptions {#assum}

## Linearity {.tabset}

Small remark, the `car` library with `crPlots` function is not applicable on model with interactions, hence we plot per predictor to check relations.

### `temp`

```{r lin temp, message=FALSE, echo=FALSE}
ggplot(data, aes(temp, cnt, colour = hr_seg)) +
  geom_point() +
  geom_smooth()
```

The relationship is not quite linear. It seems that, when the temperature gets too high, people stop renting bikes. The higher temperatures which stop people from renting bikes, do not seem to occur in the night. Therefore, the relationship between temperature and rent count seems linear in the night.

### `hum`

```{r lin hum, message=FALSE, echo=FALSE}
ggplot(data, aes(hum, cnt, colour = hr_seg)) +
  geom_point() +
  geom_smooth()
```

To combat this non-linearity issue, we have transformed the predictor variable `hum` (as mentioned earlier). This does make the interpretation of the model less intuitive.

```{r lin hum3, message=FALSE, echo=FALSE}
ggplot(data, aes(hum3, cnt, colour = hr_seg)) +
  geom_point() +
  geom_smooth()
```

This is the best transformation we could come up with. It's not perfect, but we're accepting this as sufficiently linear.

## Full rank predictor matrix


The dataset contains 2190 observations (that is, the dataset after aggregating the data). It only contains 9 variables, including the transformed humidity variable. There are definitely more observations than there are variables.

Next, we need to know whether there is a relationship between the two predictors we are using, temperature and humidity.

```{r multicol, message=FALSE, echo=FALSE}
ggplot(data, aes(temp, hum3)) +
  geom_point() +
  geom_smooth()
```

This graph shows there is no relationship between temperature and humidity, so we can conclude there is no issue of multicollinearity.

## Exogenous predictors


We need to check whether there is no relationship between the predictors of the model, and its errors. 

```{r cov e}
cov_res <- cov(predict(model2_mod), resid(model2_mod))
cov_res
```

This value is practically equal to zero.

Next, we need to know whether the mean of the errors of the model are equal to zero.

```{r pred res relation, message=FALSE, echo=FALSE}
grid.arrange(
  ggplot(data, aes(temp, resid(model2_mod))) +  geom_point() +  geom_smooth(),
  ggplot(data, aes(hum, resid(model2_mod))) +  geom_point() +  geom_smooth()
)
```

The first graph is not quite right, though the line only starts deviating from 0, in the latter part of the graph. There's less data points there as well, so it makes sense. We can make do, though.
The second graph is completely fine.

## Constant & finite variance


We need to find out whether the variance of the errors is constant over all levels of the predictor (homoscedasticity). That is shown in the first plot below.
The second plot is similar, but it shows standardized residuals (or, more accurately, their square root).

```{r homosced}
# Residual plot.
model2_mod %>% plot(1)
model2_mod %>% plot(3)
```

The first plot is fine: the red line should be y = 0. That seems to be fine.
The second plot also seems to be roughly fine. There is a weird cluster of errors in the first part of both graphs; those are responsible for the "night" rentals.

## Independent errors

The errors should be independent. Now, we can check for clustering, though we have already manually clustered the data. We can check if that clustering was sufficient.

```{r}
ICCbare(data$temp, resid(model2_mod))
ICCbare(data$hum, resid(model2_mod))
ICCbare(data$hr_seg, resid(model2_mod))
```

All ICC are close enough to 0 to conclude that there is no issue of dependence of errors.

## Normally distributed errors


The errors should be normally distributed. We can make a Q-Q plot to check whether that's true.

```{r qqplot}
plot(model2_mod, 2)
```

We want the errors to be as close to the dotted line as possible. It's not looking to great, but it's okay enough.

## Influential data points


We need to check whether the model contains any influential data points. That includes outliers and high-leverage observations. We can check the outliers first.

```{r indep res}
plot(rstudent(model2_mod)) 
```

Again, the errors should be close to y = 0. And again, it doesn't look to great, but most of the errors seem to be close to y = 0. Interestingly, the earlier outlying values seem to be below 0, while the later values seem to be above 0. It may be possible that the bike renting program started at the first day of this dataset, so it became more popular over time. There is no way to be sure, though.

Next, we need to measure Cook's distance. Outliers are included in this measure as well, but since we checked those already, we really want to know about the high-leverage points.

```{r outliers post model}
plot(cooks.distance(model2_mod))            # Seems bad, but look at scale
plot(dfbetas(model2_mod)[,1])               # Seems good
```

Nowhere, Cook's distance is high at all. So this assumption seems to be sufficiently met.

# References

<div id="refs"></div>

