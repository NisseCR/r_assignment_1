---
title: "Bike Sharing"
author: "Aga, Karla, Nisse, Ole"
date: "`r Sys.Date()`"
output: 
  html_document:
    theme: united
    number_sections: false
    toc: true
    toc_float:
      collapsed: true
    df_print: paged
bibliography: references.bib  
---

# Abstract
![](../images/bike_sharing.jpeg)  

"*Bikesharing contributes to the advent of more sustainable transportation in cities around the globe.*" [@beland]. Bikesharing programs are designed to provide short-term bicycle rental in stations dispersed throughout the cities and located near public transportation hubs [@beland]. They have numerous environmental and health benefits, such as reducing congestion, complementing other forms of public transportation and encouraging exercise [@beland]. Additionally, accessible bike rental has a lower barrier of entry than purchasing your own bike and is more convenient for out-of-town commuters.  
In principle bicycles pose a good substitute for car use in urban areas, however, they have certain limitations. Among them is the exposure of cyclists to weather while commuting compared to other means of transportation. It would be intuitive for the number of bike rentals to be dependent on current weather conditions. If that is the case, the extent of that relationship would be important information for the bikesharing companies. Potentially, the information could be a factor in variety if business decisions, including level of pricing or supply for bikes in different seasons.   

---

Considering these possible applications, this report will attempt to answer: **To what extent can weather data predict the number of bike rentals in different parts of the day?** Weather data will includes temperature, wind speed, occurrence of weather phenomena (including storms, snow and rain), 

Operationalization of the RQ:  

* Control variables â€“ possibly a table with all of the variables.  

* Drawing of the path model.  

* Methodology.  

* Data description.  

To describe our data, we retrieved the hourly count of bike rentals between the years 2022 and 2012 from the machine learning repository UC Irvine. The metadata of this dataset belongs to Capital Bikeshare in Washington DC, United States. Thus, focusing on an American population with the corresponding weather and seasonal information.  


# References

<div id="refs"></div>

# Load data

Data set is acquired from a [machine-learning repository](https://archive.ics.uci.edu/dataset/275/bike+sharing+dataset), which provided us with three files, namely:  

* `hour.csv`, hourly data of bike rentals.
* `day.csv`, daily data of bike rentals.
* `README.txt`, providing additional metadata about the file and their data.

We first specify our dependencies and read the data from `hour.csv`. We also load `day.csv`, solely for comparison purposes in our [EDA](#eda) phase.  

```{r import, message = FALSE}
library(tidyverse)
library(fastDummies)
library(kableExtra)
library(gridExtra, exclude="combine")
library(lubridate)
library(car)
```

```{r read bike}
# Source hourly data for model
source_data <- read.csv("../data/hour.csv", header = TRUE, sep = ",") %>%
  as_tibble()

# Extra daily data for EDA
day_df <- read.csv("../data/hour.csv", header = TRUE, sep = ",") %>%
  as_tibble()

# Clone source
data <- source_data

head(data)
```

We then create a sub-selection of variables that are of interest for our model; these are the control, predictor and outcome variables + variables necessary for EDA and preprocessing.

```{r select}
data <- select(data,
               dteday,
               hr, 
               weathersit, 
               temp, 
               atemp, 
               hum, 
               windspeed, 
               cnt)
```

TODO: perhaps describe columns, # of rows or the like. summarising dataframe?

# Preprocessing & EDA {#eda}

## Data Cleaning {.tabset}

### Expand `dteday` data

Expand `dteday` data by adding `dt_num` (numeric version of day, day_id so to speak).

```{r expand date}
# Converts datetime string to numeric with origin offset.
date_to_num <- function(date, offset) {
   as.integer(as.Date(date, "%Y-%m-%d")) - offset
}

# Fetch origin.
dt_offset <- source_data$dteday[1] %>%
  date_to_num(0) - 1


data <- data %>%
  mutate(
    dt_num = date_to_num(dteday, dt_offset)
  )

# Global variable for amount of unique days.
n_days <- n_distinct(data$dteday)
```

### Clustering of `hr` categories

Create clusters for `hr`  called `hr_seg`. 24 dummy codes it too much. Can use `ICC`, but requires systematic approach and might result in non-continuous clusters (as in not a single range of hours, e.g. 2, 7, 8).

Instead divide based on relation to outcome variable.
```{r hour cut}
# Shift the `hr` data by 2 and increment the hour 23 for easier binning via the cut function.
data <- data %>%
  mutate(hr_idx = hr + 2)

data$hr_idx[data$hr == 23] <- 1

# Cut the 24 hour entries in 3 categories.
data <- data %>%
  mutate(hr_seg = cut(
    hr_idx,
    breaks = c(0, 8, 16, 24),
    labels = c("night", "morning-noon", "eve")
  ))
```

Check whether segmenting of `hr` is applied correctly by looking at single day data.

```{r bin check}
# Check output for single day.
data %>%
  filter(dteday == "2011-01-01") %>%
  arrange(hr) %>%
  select(hr, hr_seg) %>%
  head(24)
```

Segments were chosen based on `hr~cnt` data. Segments needed to be of equal size.

```{r determine segment, message=FALSE}
# Create a `mode` function for aggregation.
mode <- function(x) {
    which.max(table(x))
}

# Plot hr~cnt with current segmentation indicator.
data %>%
  group_by(hr, hr_seg) %>%
  summarise(
    cnt = sum(cnt)
  ) %>%
  ggplot(aes(hr, cnt, fill = hr_seg)) +
    geom_bar(stat = "identity")
```

## Summary/stats?

Summary of our data.

```{r summary}
summary(data)
```

Data contains `r n_days` unique days, meaning that the entirety of 2011 (365 days) and 2012 (366 days) was recorded.

## Distributions {#dists}

Distributions of variables.

```{r distributions, echo=FALSE, message=FALSE}
grid.arrange(
    ggplot(data, aes(hr)) + geom_histogram(binwidth = 1),
    ggplot(data, aes(weathersit)) + geom_histogram(binwidth = 1),
    ggplot(data, aes(temp)) + geom_histogram(),
    ggplot(data, aes(atemp)) + geom_histogram(),
    ggplot(data, aes(hum)) + geom_histogram(),
    ggplot(data, aes(windspeed)) + geom_histogram(),
    ggplot(data, aes(cnt)) + geom_histogram()
)
```

Notice the following:

-   Missing records in some `hr` categories.
-   Occurrence gap in `windspeed` distribution.
-   Category 4 of `weathersit` is barely present. (categorical outlier)

## Outliers {.tabset}

Outlier detection using quantiles.  
```{r outliers, echo=FALSE, message=FALSE}
grid.arrange(
    ggplot(data, aes(temp)) + geom_boxplot(),
    ggplot(data, aes(atemp)) + geom_boxplot(),
    ggplot(data, aes(hum)) + geom_boxplot(),
    ggplot(data, aes(windspeed)) + geom_boxplot(),
    ggplot(data, aes(cnt)) + geom_boxplot()
)
```

Notice the following:

-   Large amount of outliers in `cnt` (outcome variables (due to right-skewed distr).
-   Some outliers in `windspeed`.
-   3x `0.00` values of `hum`.

### Rental count outliers
Large amount of `cnt` outliers is due to low rental count during the night, which shifts the median to a lower value. `hr_seg` acts as moderator, so better to check data displays *per* `hr_seg` cluster.  

```{r cnt outliers, echo=FALSE, message=FALSE}
ggplot(data, aes(cnt, colour = hr_seg)) + geom_boxplot()

ggplot(data, aes(cnt)) + geom_histogram() + facet_wrap(vars(hr_seg))
```

Even then we see that distributions per `hr_seq` are heavily right-skewed, explaining the multitude of outliers.  
Looking at the tail-end of the `cnt` values, these seem to be non-error outliers. Furthermore they seem to be reasonable values due to right-skewness, hence we don't remove them.

### Windspeed outliers

Again right-skewed, hence large values are seen as outliers. Do notice how there's gap between 0 values and the first non-zero values, specifically:  
```{r windspeed outliers}
data %>%
  group_by(windspeed) %>%
  summarise(n = n()) %>%
  arrange(windspeed) %>%
  head()
```

Might be due to sensor threshold for measuring windspeed. In any case, these values fall within the distribution, it is only odd that there's a small increment between the `0.00` occurences and the values thereafter (e.g. `0.0869`).
These might also be possible missing values which are replaced with `0.00`.  
In any case, we cannot know for certain. Since the number of occurrences for `0.00` is in line with neigbouring values, we choose to keep them.

### Humidity outliers

`hum` is left-skewed.
```{r hum outliers}
data %>%
  group_by(hum) %>%
  summarise(n = n()) %>%
  arrange(hum) %>%
  head()
```

## Missing data

Check standard NA values. There are none.

```{r missing standard}
anyNA(data)
```

### Missing records for hour

Some `hr` values seem to have a lower amount of occurrences than others, as can be seen in distribution plot of [Distributions](#dists)

```{r hr missing}
# Count the amount of records per hour.
# Also add a column for amount of *missing* records.
hr_df <- data %>%
  group_by(hr) %>%
  summarise(
    n = n(),
    n_missing_days = n_days - n) # using global variable `n_days`.

ggplot(hr_df, aes(hr, n_missing_days)) +
  geom_bar(stat = "identity")
```

Determine where missing records are located. Seems that a system outtage (or the like) was present on `2012-10-29` and `2012-10-30`, with a combined total of `35` missing records.
```{r missing location, message = FALSE}
# Create dataframe with amount of missing records per day.
missing_df <- data %>%
  group_by(dteday, dt_num) %>%
  summarise(
    n_records = n(),
    n_missing_records = 24 - n_records
  ) %>%
  filter(n_missing_records > 0) %>%
  arrange(desc(n_missing_records)) %>%
  select(dteday, n_missing_records)

head(missing_df, 10)
```

`n_missing_records` is the amount of missing entries on that particalur day.

## Covariance {.tabset}

### Covariance with predictor `atemp`

Have suspicion that `atemp` might be correlated with `temp`, `windspeed` and `hum`, since it is a combined variable of the three (mayhaps). Justify this:

```{r atemp covar, echo=FALSE}
grid.arrange(
  ggplot(data, aes(temp, atemp)) + geom_point(),
  ggplot(data, aes(windspeed, atemp)) + geom_point(),
  ggplot(data, aes(hum, atemp)) + geom_point(),
  nrow = 1
)
```

Can conclude that predictor variables `atemp` and `temp` are highly correlated, whilst `hum` and `windspeed` have a weaker relation with `atemp`.

TODO reason why not to include `atemp` in model comparison.

### Covariance with outcome variable `cnt`

Create covariance table of predictor vs outcome variables.
```{r cnt covar table}
covar_df <- data.frame(
  temp = cor(data$cnt, data$temp),
  hum = cor(data$cnt, data$hum),
  windspeed = cor(data$cnt, data$windspeed),
  weathersit = cor(data$cnt, data$weathersit)
)

covar_df
```

Remark:  

- Non-linear relation between `hum` and `cnt`
- Negative relation between `windspeed` and `cnt`
- Positive relation between `temp` and `cnt`, up until high temperatures are reached (ppl dont like biking in hot water, don't blame them).

```{r cnt covar scatter, echo=FALSE, message=FALSE}
plot_cnt_covar <- function(plot) {
  plot + 
    geom_point() +
    geom_smooth(method = 'loess') +
    facet_wrap(vars(hr_seg))
}

ggplot(data, aes(temp, cnt)) %>% plot_cnt_covar()
ggplot(data, aes(windspeed, cnt)) %>% plot_cnt_covar()
ggplot(data, aes(hum, cnt)) %>% plot_cnt_covar()
```

## Data Aggregation
After having created `hr_seq`, we aggregate the data based on both the date (`dteday`) and the hour segments (`hr_seg`. In case of dichotomous variables, we take the `mode` of the variable, with earlier defined function.
```{r aggregate hour, message=FALSE}
# Aggregate over `hr_bin` factor.
data <- data %>%
    group_by(dteday, hr_seg) %>%
    summarize(
        temp = mean(temp),
        atemp = mean(atemp),
        hum = mean(hum),
        windspeed = mean(atemp),
        weathersit = mode(weathersit),
        cnt = sum(cnt)
    )
```



# Model creation & comparison

Later on in [Assumptions](#assum) we concluded a non-linear (higher-order) relation between `hum` and `cnt`. To approximate a linear relation, we've transformed the data to `f(x) = x^3`, saved in column `hum3`.  

```{r solve non lin}
data$hum3 = data$hum^3
```

Create simple and complex models. Order is based on covariance table (high to low).
```{r model creation}
# Create models.
model1        <- lm(cnt ~ temp, data)
model2        <- lm(cnt ~ temp + hum3, data)
model3        <- lm(cnt ~ temp + hum3 + weathersit, data)
model4        <- lm(cnt ~ temp + hum3 + weathersit + windspeed, data)

# Include moderator for model of choice (#2), for comparison analysis.
model2_mod    <- lm(cnt ~ (temp + hum3)* hr_seg, data)
```

Comparison results table.
```{r comparison}
RMSE <- function(model) {
  model$residuals^2 %>% mean()
}

comp_df <- data.frame(
  model = c('model1', 'model2', 'model3', 'model4', 'model2_mod'),
  predictors = c('temp', 'temp + hum3', 'temp + hum3 + weathersit', 'temp + hum3 + weathersit + windspeed', 'temp + hum3'),
  moderator = c('', '', '', '', 'hr_seg'),
  AIC = c(AIC(model1), AIC(model2), AIC(model3), AIC(model4), AIC(model2_mod)),
  BIC = c(BIC(model1), BIC(model2), BIC(model3), BIC(model4), BIC(model2_mod)),
  RMSE = c(RMSE(model1), RMSE(model2), RMSE(model3), RMSE(model4), RMSE(model2_mod))
)


comp_df
```

Anova tests.
```{r anovas}
# Simple and complex model
anova(model1, model2)
anova(model2, model3)
anova(model3, model4)

# Test addition of moderator
anova(model2, model2_mod)
```

# Assumptions {#assum}

## Linearity {.tabset}

Small remark, the `car` library with `crPlots` function is not applicable on model with interactions, hence we plot per predictor to check relations.

### `temp`

```{r lin temp, message=FALSE, echo=FALSE}
ggplot(data, aes(temp, cnt, colour = hr_seg)) +
  geom_point() +
  geom_smooth()
```

### `hum`

```{r lin hum, message=FALSE, echo=FALSE}
ggplot(data, aes(hum, cnt, colour = hr_seg)) +
  geom_point() +
  geom_smooth()
```

To combat this non-linearity issue, we have transformed the predictor variable `hum` (as mentioned earlier). This does make the interpretation of the model less intuitive.

```{r lin hum3, message=FALSE, echo=FALSE}
ggplot(data, aes(hum3, cnt, colour = hr_seg)) +
  geom_point() +
  geom_smooth()
```

## Full rank predictor matrix

Check:

- $N > P$, where $N$ is the number of rows and $P$ are the amount of predictors within the model.
- Predictors may not show linear relation with one another.

Data has `n = `r nrow(data)`` rows, which is greater than the number of predictors `P = 2`.  

Check absence of multicollinearity:

```{r multicol, message=FALSE, echo=FALSE}
ggplot(data, aes(temp, hum3)) +
  geom_point() +
  geom_smooth()
```

Can indeed conclude there is no linear combination between `hum3` and `temp`, our predictors.

## Exogenous predictors

Check:  

- $Cov(\hat{Y}, \epsilon) = 0$
- $E[\epsilon_n] = 0$
- No relation between predictors and residuals of model.

```{r cov e}
 cov_res <- cov(predict(model2_mod), resid(model2_mod))
```

Covariance between `predicted` and `residuals` is ``r cov_res``.

```{r pred res relatoin, message=FALSE, echo=FALSE}
grid.arrange(
  ggplot(data, aes(temp, resid(model2_mod))) +  geom_point() +  geom_smooth(),
  ggplot(data, aes(hum, resid(model2_mod))) +  geom_point() +  geom_smooth()
)
```

## Constant & finite variance

```{r homosced}
# Residual plot.
model2_mod %>% plot(1)
model2_mod %>% plot(3)
```

## Independent errors

```{r indep res}
plot(rstudent(model2_mod)) 
```


## Normally distributed errors

```{r qqplot}
plot(model2_mod, 2)
```

## Influential data points
```{r outliers post model}
plot(cooks.distance(model2_mod))            # Seems bad, but look at scale
plot(dfbetas(model2_mod)[,1])               # Seems good
```


